{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cZ-qDpFDJAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d2253f-85eb-44ad-d439-1c10470e373b"
      },
      "source": [
        "!gdown --id 1pb7gEkctrVrJA79EAIo7H7nuzD6uV1fW\n",
        "!gdown --id 1oIeAE9HXXKWPcYa-AZ0ht5ef6sKe_Vh_\n",
        "!gdown --id 10rAuIDvsYR2yDiCqP7GmYGPc-UmtLbJb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pb7gEkctrVrJA79EAIo7H7nuzD6uV1fW\n",
            "To: /content/train.csv\n",
            "100% 31.7M/31.7M [00:00<00:00, 86.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oIeAE9HXXKWPcYa-AZ0ht5ef6sKe_Vh_\n",
            "To: /content/test.csv\n",
            "100% 141k/141k [00:00<00:00, 20.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10rAuIDvsYR2yDiCqP7GmYGPc-UmtLbJb\n",
            "To: /content/sample_submission.csv\n",
            "100% 75.0/75.0 [00:00<00:00, 155kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJZtK2SALemL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c4b2a2-dc9b-4f9b-f5fd-cf69e1ada300"
      },
      "source": [
        "!pip install --quiet transformers\n",
        "!pip install --quiet datasets \n",
        "!pip install --quiet SentencePiece\n",
        "!pip install --quiet pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 61.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 46.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 30.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 290 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 54.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 26.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 65.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 160 kB 46.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 54.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 925 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 40.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 329 kB 59.8 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIDhy5YWDXJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7947bfdd-0c2e-4ddc-fa96-44877b831047"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn import model_selection\n",
        "from transformers import RobertaTokenizer, RobertaForQuestionAnswering\n",
        "import pytorch_lightning as pl\n",
        "from tqdm import tqdm\n",
        "import transformers\n",
        "from transformers import (WEIGHTS_NAME,AdamW,AutoConfig,AutoModel,AutoTokenizer,get_cosine_schedule_with_warmup,\n",
        "    get_linear_schedule_with_warmup,logging,MODEL_FOR_QUESTION_ANSWERING_MAPPING,)\n",
        "\n",
        "from sklearn import model_selection\n",
        "pl.seed_everything(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVHoTMnl3dMR"
      },
      "source": [
        "class Config:\n",
        "    # model\n",
        "    model_type = 'xlm_roberta'\n",
        "    model_name_or_path = \"deepset/xlm-roberta-large-squad2\"\n",
        "    config_name = \"deepset/xlm-roberta-large-squad2\"\n",
        "    gradient_accumulation_steps = 2\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # tokenizer\n",
        "    tokenizer_name = \"deepset/xlm-roberta-large-squad2\"\n",
        "    max_seq_length = 384\n",
        "    doc_stride = 128\n",
        "\n",
        "    # train\n",
        "    epochs = 1\n",
        "    train_batch_size = 4\n",
        "    eval_batch_size = 8\n",
        "\n",
        "    # optimizer\n",
        "    optimizer_type = 'AdamW'\n",
        "    learning_rate = 1.5e-5\n",
        "    weight_decay = 1e-2\n",
        "    epsilon = 1e-8\n",
        "    max_grad_norm = 1.0\n",
        "\n",
        "    # scheduler\n",
        "    decay_name = 'linear-warmup'\n",
        "    warmup_ratio = 0.1\n",
        "\n",
        "    # logging\n",
        "    logging_steps = 10\n",
        "\n",
        "    # evaluate\n",
        "    output_dir = 'output'\n",
        "    seed = 2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LMuZ_VPjDIm"
      },
      "source": [
        "train_df = pd.read_csv('/content/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn9MxQNIL_k5"
      },
      "source": [
        "def convert_answers(row):\n",
        "    return {'answer_start': [row[0]], 'text': [row[1]]}\n",
        "\n",
        "train_df['answers'] = train_df[['answer_start', 'answer_text']].apply(convert_answers, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVkxruVBM-0K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "391c6d05-ace8-4d9c-a72a-e8d6b116ca04"
      },
      "source": [
        "train_df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>language</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1109</th>\n",
              "      <td>26f356026</td>\n",
              "      <td>स्वामी निगमानन्द परमहंस (18 अगस्त 1880 - 29 नव...</td>\n",
              "      <td>स्वामी निगमानन्द परमहंस के तन्त्र गुरु कौन थे?</td>\n",
              "      <td>बामाक्षेपा</td>\n",
              "      <td>2691</td>\n",
              "      <td>hindi</td>\n",
              "      <td>{'answer_start': [2691], 'text': ['बामाक्षेपा']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1110</th>\n",
              "      <td>31179f1bb</td>\n",
              "      <td>भरत मुनि ने नाट्यशास्त्र नामक प्रसिद्ध ग्रन्थ ...</td>\n",
              "      <td>नित्यशास्त्र किसने लिखा है?</td>\n",
              "      <td>भरत मुनि</td>\n",
              "      <td>0</td>\n",
              "      <td>hindi</td>\n",
              "      <td>{'answer_start': [0], 'text': ['भरत मुनि']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1111</th>\n",
              "      <td>0d35dc007</td>\n",
              "      <td>अग्नि पंचम (अग्नि-५) भारत की अन्तरमहाद्वीपीय ब...</td>\n",
              "      <td>अग्नि पंचम(५) मिसाइल की लम्बाई कितने मीटर है?</td>\n",
              "      <td>17</td>\n",
              "      <td>155</td>\n",
              "      <td>hindi</td>\n",
              "      <td>{'answer_start': [155], 'text': ['17']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1112</th>\n",
              "      <td>7f997884d</td>\n",
              "      <td>जलाल उद्दीन मोहम्मद अकबर () (१५ अक्तूबर, १५४२-...</td>\n",
              "      <td>मुगल सम्राट अकबर की मृत्यु किस वर्ष में हुई थी?</td>\n",
              "      <td>२७ अक्तूबर, १६०५</td>\n",
              "      <td>46</td>\n",
              "      <td>hindi</td>\n",
              "      <td>{'answer_start': [46], 'text': ['२७ अक्तूबर, १...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1113</th>\n",
              "      <td>ee569fe45</td>\n",
              "      <td>अमेरिका में जन्मीं अभिनेत्री तथा फैशन डिज़ाइनर...</td>\n",
              "      <td>लीजा रे की पहली फिल्म का नाम क्या था?</td>\n",
              "      <td>नेताजी</td>\n",
              "      <td>2017</td>\n",
              "      <td>hindi</td>\n",
              "      <td>{'answer_start': [2017], 'text': ['नेताजी']}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                                            answers\n",
              "1109  26f356026  ...   {'answer_start': [2691], 'text': ['बामाक्षेपा']}\n",
              "1110  31179f1bb  ...        {'answer_start': [0], 'text': ['भरत मुनि']}\n",
              "1111  0d35dc007  ...            {'answer_start': [155], 'text': ['17']}\n",
              "1112  7f997884d  ...  {'answer_start': [46], 'text': ['२७ अक्तूबर, १...\n",
              "1113  ee569fe45  ...       {'answer_start': [2017], 'text': ['नेताजी']}\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRB4Wf8Qznqc"
      },
      "source": [
        "def prepare_train_features(args, example, tokenizer):\n",
        "\n",
        "    example[\"question\"] = example[\"question\"].lstrip()\n",
        "    tokenized_example = tokenizer(example[\"question\"], example[\"context\"], truncation=\"only_second\", max_length=args.max_seq_length,\n",
        "        stride=args.doc_stride, return_overflowing_tokens=True, return_offsets_mapping=True, padding=\"max_length\")\n",
        "\n",
        "    '''\n",
        "    tokenized samples looks like: \n",
        "    [CLS] 0 0 ... 0 [SEP] 1 1 ... 1 [SEP]\n",
        "    [CLS] Question [SEP] Context [SEP]\n",
        "\n",
        "    '''\n",
        "\n",
        "    sample_mapping = tokenized_example.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    offset_mapping = tokenized_example.pop(\"offset_mapping\")\n",
        "\n",
        "    features = []\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        feature = {}\n",
        "\n",
        "        input_ids = tokenized_example[\"input_ids\"][i]\n",
        "        attention_mask = tokenized_example[\"attention_mask\"][i]\n",
        "\n",
        "        feature['input_ids'] = input_ids\n",
        "        feature['attention_mask'] = attention_mask\n",
        "        feature['offset_mapping'] = offsets\n",
        "\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "        # print(cls_index)\n",
        "        token_type_ids = tokenized_example.sequence_ids(i)\n",
        "\n",
        "\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = example[\"answers\"]\n",
        "        # print(answers)\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            print(\"HHHHHHHHHHHHHHHHHHHHHHHH\")\n",
        "            feature[\"start_position\"] = cls_index\n",
        "            feature[\"end_position\"] = cls_index\n",
        "\n",
        "        else:\n",
        "            print(\"HERE\" , token_type_ids)\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "            token_start_index = 0\n",
        "\n",
        "            #jab tak tokentypeids me 1 tak nahi pahuch jate... that is context.. keep increasing the start index\n",
        "            #this means we want the index where context begins\n",
        "            # while token_type_ids[token_start_index] != 1:\n",
        "            #     token_start_index += 1\n",
        "\n",
        "            token_start_index = token_type_ids.index(1)\n",
        "\n",
        "            token_end_index = len(input_ids) - 1\n",
        "\n",
        "            while token_type_ids[token_end_index] != 1:\n",
        "                token_end_index -= 1\n",
        "\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                feature[\"start_position\"] = cls_index\n",
        "                feature[\"end_position\"] = cls_index\n",
        "            else:\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                feature[\"start_position\"] = token_start_index - 1\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                feature[\"end_position\"] = token_end_index + 1\n",
        "\n",
        "        features.append(feature)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uXvluve0SDb"
      },
      "source": [
        "def make_loader(args, train_df):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name)\n",
        "    train_set, valid_set = model_selection.train_test_split(train_df, test_size=0.2,random_state = 0)\n",
        "\n",
        "    train_features, valid_features = [],[]\n",
        "\n",
        "    for idx, row in tqdm(train_set.iterrows(), total=train_set.shape[0]):\n",
        "        train_features += prepare_train_features(args, row, tokenizer)\n",
        "\n",
        "    for idx, row in tqdm(valid_set.iterrows(),total = valid_set.shape[0]):\n",
        "        valid_features += prepare_train_features(args,row,tokenizer)\n",
        "        \n",
        "    return train_features, valid_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxBgeFs32D08"
      },
      "source": [
        "args = Config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc0HvI5b2Hh0"
      },
      "source": [
        "train_feat, valid_feat =make_loader(args, train_df.head(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdLnSfaqUoo"
      },
      "source": [
        "class DataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        pass\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        pass\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMUC7wUaZUJo"
      },
      "source": [
        "class Hyperparameters():\n",
        "    #preproc\n",
        "    tokenizer = \n",
        "    model = \n",
        "    config = \n",
        "\n",
        "    #model\n",
        "    learning_rate = \n",
        "    scheduler = \n",
        "    optimizer = \n",
        "    regularization = \n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}